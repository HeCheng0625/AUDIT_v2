{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process FreeSound and FSD50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "import torchaudio\n",
    "import torch\n",
    "from librosa.util import normalize\n",
    "from librosa.filters import mel as librosa_mel_fn\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from scipy.io.wavfile import read, write\n",
    "MAX_WAV_VALUE = 32768.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(full_path):\n",
    "    sampling_rate, data = read(full_path)\n",
    "    return data, sampling_rate\n",
    "\n",
    "def dynamic_range_compression(x, C=1, clip_val=1e-5):\n",
    "    return np.log(np.clip(x, a_min=clip_val, a_max=None) * C)\n",
    "\n",
    "def dynamic_range_decompression(x, C=1):\n",
    "    return np.exp(x) / C\n",
    "\n",
    "def dynamic_range_compression_torch(x, C=1, clip_val=1e-5):\n",
    "    return torch.log(torch.clamp(x, min=clip_val) * C)\n",
    "\n",
    "def dynamic_range_decompression_torch(x, C=1):\n",
    "    return torch.exp(x) / C\n",
    "\n",
    "def spectral_normalize_torch(magnitudes):\n",
    "    output = dynamic_range_compression_torch(magnitudes)\n",
    "    return output\n",
    "\n",
    "def spectral_de_normalize_torch(magnitudes):\n",
    "    output = dynamic_range_decompression_torch(magnitudes)\n",
    "    return output\n",
    "\n",
    "mel_basis = {}\n",
    "hann_window = {}\n",
    "\n",
    "def mel_spectrogram(y, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center=False):\n",
    "    if torch.min(y) < -1.:\n",
    "        print('min value is ', torch.min(y))\n",
    "    if torch.max(y) > 1.:\n",
    "        print('max value is ', torch.max(y))\n",
    "\n",
    "    global mel_basis, hann_window\n",
    "    if fmax not in mel_basis:\n",
    "        mel = librosa_mel_fn(sr=sampling_rate, n_fft=n_fft, n_mels=num_mels, fmin=fmin, fmax=fmax)\n",
    "        mel_basis[str(fmax)+'_'+str(y.device)] = torch.from_numpy(mel).float().to(y.device)\n",
    "        hann_window[str(y.device)] = torch.hann_window(win_size).to(y.device)\n",
    "\n",
    "    y = torch.nn.functional.pad(y.unsqueeze(1), (int((n_fft-hop_size)/2), int((n_fft-hop_size)/2)), mode='reflect')\n",
    "    y = y.squeeze(1)\n",
    "\n",
    "    spec = torch.stft(y, n_fft, hop_length=hop_size, win_length=win_size, window=hann_window[str(y.device)],\n",
    "                      center=center, pad_mode='reflect', normalized=False, onesided=True, return_complex=False)\n",
    "\n",
    "    spec = torch.sqrt(spec.pow(2).sum(-1)+(1e-9))\n",
    "\n",
    "    spec = torch.matmul(mel_basis[str(fmax)+'_'+str(y.device)], spec)\n",
    "    spec = spectral_normalize_torch(spec)\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222935"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsd_json_file = \"/blob/v-yuancwang/WavCaps/fsd_final_2s.json\"\n",
    "with open(fsd_json_file, \"r\") as f:\n",
    "    fsd_infos = json.load(f)\n",
    "fsd_infos = fsd_infos['data']\n",
    "# print(len(fsd_infos))\n",
    "fsd_infos_simple = []\n",
    "for info in fsd_infos:\n",
    "    fsd_infos_simple.append({\"id\": info[\"id\"], \"file_name\": info[\"file_name\"],\n",
    "                             \"download_link\": info[\"download_link\"],\n",
    "                             \"caption\": info[\"caption\"],\n",
    "                             \"duration\": info[\"duration\"]})\n",
    "# print(len(fsd_infos_simple))\n",
    "# for info in fsd_infos_simple[:5]:\n",
    "#     print(info)\n",
    "id_caption_dict = {}\n",
    "for info in fsd_infos_simple:\n",
    "    id_caption_dict[info['id']] = info['caption']\n",
    "len(id_caption_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsd_origin_path = \"/blob/v-yuancwang/WavCaps/FreeSound/wav_origin\"\n",
    "fsd_wav_path = \"/blob/v-yuancwang/WavCaps/FreeSound/wav\"\n",
    "fsd_mel_path = \"/blob/v-yuancwang/WavCaps/FreeSound/mel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['27785.wav', '191992.wav', '427941.wav', '197305.wav', '207132.wav']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsd_wav_origin_lists = os.listdir(fsd_origin_path)\n",
    "print(len(fsd_wav_origin_lists))\n",
    "fsd_wav_origin_lists[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _2s_lists = []\n",
    "# _5s_lists = []\n",
    "# _10s_lists = []\n",
    "\n",
    "# for wav_id in tqdm(fsd_wav_origin_lists[:]):\n",
    "#     try:\n",
    "#         wav, sr = librosa.load(os.path.join(fsd_origin_path, wav_id), sr=16000)\n",
    "#     except:\n",
    "#         continue\n",
    "\n",
    "#     if len(wav) >= 16000 * 10:\n",
    "#         wav = wav[:16000 * 10]\n",
    "#     elif len(wav) < 16000 * 10 and len(wav) >= 16000 * 7:\n",
    "#         wav = np.pad(wav, ((0, 16000 * 10 - len(wav))), 'wrap')\n",
    "#     elif len(wav) < 16000 * 7 and len(wav) >= 16000 * 5:\n",
    "#         wav = wav[:16000 * 5]\n",
    "#     elif len(wav) < 16000 * 5 and len(wav) >= 16000 * 2.5:\n",
    "#         wav = np.pad(wav, ((0, 16000 * 5 - len(wav))), 'wrap')\n",
    "#     elif len(wav) < 16000 * 2.5 and len(wav) >= 16000 * 2:\n",
    "#         wav = wav[:16000 * 2]\n",
    "#     else:\n",
    "#         wav = np.pad(wav, ((0, 16000 * 2 - len(wav))), 'wrap')\n",
    "#     wav = np.clip(wav, -1, 1)\n",
    "\n",
    "#     x = torch.FloatTensor(wav)\n",
    "#     x = mel_spectrogram(x.unsqueeze(0), n_fft=1024, num_mels=80, sampling_rate=16000,\n",
    "#                         hop_size=256, win_size=1024, fmin=0, fmax=8000)\n",
    "#     spec = x.cpu().numpy()[0]\n",
    "#     np.save(os.path.join(fsd_mel_path, wav_id.replace(\".wav\", \".npy\")), spec)\n",
    "\n",
    "#     wav = wav * MAX_WAV_VALUE\n",
    "#     wav = wav.astype('int16')\n",
    "#     write(os.path.join(fsd_wav_path, wav_id), 16000, wav)\n",
    "\n",
    "\n",
    "# print(len(_2s_lists))\n",
    "# print(len(_5s_lists))\n",
    "# print(len(_10s_lists))\n",
    "\n",
    "# with open(\"/home/v-yuancwang/AUDIT_v2/medata_infos/fsd_2s.json\", \"w\") as f:\n",
    "#     json.dump(_2s_lists, f)\n",
    "# with open(\"/home/v-yuancwang/AUDIT_v2/medata_infos/fsd_5s.json\", \"w\") as f:\n",
    "#     json.dump(_5s_lists, f)\n",
    "# with open(\"/home/v-yuancwang/AUDIT_v2/medata_infos/fsd_10s.json\", \"w\") as f:\n",
    "#     json.dump(_10s_lists, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsd50k_dev_path = \"/blob/v-yuancwang/FSD50K/FSD50K.dev_audio\"\n",
    "fsd50k_eval_path = \"/blob/v-yuancwang/FSD50K/FSD50K.eval_audio\"\n",
    "fsd50k_dev_lists = os.listdir(fsd50k_dev_path)\n",
    "fsd50k_eval_lists = os.listdir(fsd50k_eval_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40966 10231\n"
     ]
    }
   ],
   "source": [
    "print(len(fsd50k_dev_lists), len(fsd50k_eval_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40966/40966 [00:50<00:00, 817.61it/s]\n",
      "100%|██████████| 10231/10231 [00:12<00:00, 827.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "25508"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num = 0\n",
    "for wav_id in tqdm(fsd50k_dev_lists):\n",
    "    if wav_id not in set(fsd_wav_origin_lists):\n",
    "        total_num += 1\n",
    "for wav_id in tqdm(fsd50k_eval_lists):\n",
    "    if wav_id not in set(fsd_wav_origin_lists):\n",
    "        total_num += 1\n",
    "total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsd50k_wav_path = \"/blob/v-yuancwang/WavCaps/FSD50K/wav\"\n",
    "fsd50k_mel_path = \"/blob/v-yuancwang/WavCaps/FSD50K/mel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51197"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_caption_dict = {}\n",
    "dev_df = pd.read_csv(\"/blob/v-yuancwang/FSD50K/FSD50K.ground_truth/dev.csv\")\n",
    "for id, labels in zip(dev_df['fname'], dev_df['labels']):\n",
    "    id_caption_dict[str(id)] = labels.split(\",\")[0]\n",
    "eval_df = pd.read_csv(\"/blob/v-yuancwang/FSD50K/FSD50K.ground_truth/eval.csv\")\n",
    "for id, labels in zip(eval_df['fname'], eval_df['labels']):\n",
    "    id_caption_dict[str(id)] = labels.split(\",\")[0]\n",
    "len(id_caption_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12871/707816545.py:14: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  wav, sr = librosa.load(os.path.join(fsd50k_dev_path, wav_id), sr=16000)\n",
      "/opt/conda/envs/control/lib/python3.8/site-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10554\n",
      "7198\n",
      "5280\n"
     ]
    }
   ],
   "source": [
    "_2s_lists = []\n",
    "_5s_lists = []\n",
    "_10s_lists = []\n",
    "\n",
    "fsd_wav_origin_set = set(fsd_wav_origin_lists)\n",
    "\n",
    "for wav_id in fsd50k_dev_lists[:]+fsd50k_eval_lists[:]:\n",
    "    if wav_id in set(fsd_wav_origin_set):\n",
    "        continue\n",
    "    # else:\n",
    "    #     print(wav_id)\n",
    "\n",
    "    try:\n",
    "        wav, sr = librosa.load(os.path.join(fsd50k_dev_path, wav_id), sr=16000)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if len(wav) >= 16000 * 10:\n",
    "        wav = wav[:16000 * 10]\n",
    "        _10s_lists.append({\"mel\": os.path.join(fsd50k_mel_path, wav_id.replace(\".wav\", \".npy\")),\n",
    "                           \"caption\": id_caption_dict[wav_id.replace(\".wav\", \"\")].replace(\"_\", \" \", 10)})\n",
    "    elif len(wav) < 16000 * 10 and len(wav) >= 16000 * 7:\n",
    "        wav = np.pad(wav, ((0, 16000 * 10 - len(wav))), 'wrap')\n",
    "        _10s_lists.append({\"mel\": os.path.join(fsd50k_mel_path, wav_id.replace(\".wav\", \".npy\")),\n",
    "                           \"caption\": id_caption_dict[wav_id.replace(\".wav\", \"\")].replace(\"_\", \" \", 10)})\n",
    "    elif len(wav) < 16000 * 7 and len(wav) >= 16000 * 5:\n",
    "        wav = wav[:16000 * 5]\n",
    "        _5s_lists.append({\"mel\": os.path.join(fsd50k_mel_path, wav_id.replace(\".wav\", \".npy\")),\n",
    "                           \"caption\": id_caption_dict[wav_id.replace(\".wav\", \"\")].replace(\"_\", \" \", 10)})\n",
    "    elif len(wav) < 16000 * 5 and len(wav) >= 16000 * 2.5:\n",
    "        wav = np.pad(wav, ((0, 16000 * 5 - len(wav))), 'wrap')\n",
    "        _5s_lists.append({\"mel\": os.path.join(fsd50k_mel_path, wav_id.replace(\".wav\", \".npy\")),\n",
    "                           \"caption\": id_caption_dict[wav_id.replace(\".wav\", \"\")].replace(\"_\", \" \", 10)})\n",
    "    elif len(wav) < 16000 * 2.5 and len(wav) >= 16000 * 2:\n",
    "        wav = wav[:16000 * 2]\n",
    "        _2s_lists.append({\"mel\": os.path.join(fsd50k_mel_path, wav_id.replace(\".wav\", \".npy\")),\n",
    "                           \"caption\": id_caption_dict[wav_id.replace(\".wav\", \"\")].replace(\"_\", \" \", 10)})\n",
    "    else:\n",
    "        wav = np.pad(wav, ((0, 16000 * 2 - len(wav))), 'wrap')\n",
    "        _2s_lists.append({\"mel\": os.path.join(fsd50k_mel_path, wav_id.replace(\".wav\", \".npy\")),\n",
    "                           \"caption\": id_caption_dict[wav_id.replace(\".wav\", \"\")].replace(\"_\", \" \", 10)})\n",
    "    wav = np.clip(wav, -1, 1)\n",
    "\n",
    "    x = torch.FloatTensor(wav)\n",
    "    x = mel_spectrogram(x.unsqueeze(0), n_fft=1024, num_mels=80, sampling_rate=16000,\n",
    "                        hop_size=256, win_size=1024, fmin=0, fmax=8000)\n",
    "    spec = x.cpu().numpy()[0]\n",
    "    np.save(os.path.join(fsd50k_mel_path, wav_id.replace(\".wav\", \".npy\")), spec)\n",
    "\n",
    "    wav = wav * MAX_WAV_VALUE\n",
    "    wav = wav.astype('int16')\n",
    "    write(os.path.join(fsd50k_wav_path, wav_id), 16000, wav)\n",
    "\n",
    "\n",
    "print(len(_2s_lists))\n",
    "print(len(_5s_lists))\n",
    "print(len(_10s_lists))\n",
    "\n",
    "with open(\"/home/v-yuancwang/AUDIT_v2/medata_infos/fsd50k_2s.json\", \"w\") as f:\n",
    "    json.dump(_2s_lists, f)\n",
    "with open(\"/home/v-yuancwang/AUDIT_v2/medata_infos/fsd50k_5s.json\", \"w\") as f:\n",
    "    json.dump(_5s_lists, f)\n",
    "with open(\"/home/v-yuancwang/AUDIT_v2/medata_infos/fsd50k_10s.json\", \"w\") as f:\n",
    "    json.dump(_10s_lists, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
