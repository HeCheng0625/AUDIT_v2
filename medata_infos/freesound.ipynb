{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process FreeSound and FSD50K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io.wavfile import read\n",
    "import torchaudio\n",
    "import torch\n",
    "from librosa.util import normalize\n",
    "from librosa.filters import mel as librosa_mel_fn\n",
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from scipy.io.wavfile import read, write\n",
    "MAX_WAV_VALUE = 32768.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_wav(full_path):\n",
    "    sampling_rate, data = read(full_path)\n",
    "    return data, sampling_rate\n",
    "\n",
    "def dynamic_range_compression(x, C=1, clip_val=1e-5):\n",
    "    return np.log(np.clip(x, a_min=clip_val, a_max=None) * C)\n",
    "\n",
    "def dynamic_range_decompression(x, C=1):\n",
    "    return np.exp(x) / C\n",
    "\n",
    "def dynamic_range_compression_torch(x, C=1, clip_val=1e-5):\n",
    "    return torch.log(torch.clamp(x, min=clip_val) * C)\n",
    "\n",
    "def dynamic_range_decompression_torch(x, C=1):\n",
    "    return torch.exp(x) / C\n",
    "\n",
    "def spectral_normalize_torch(magnitudes):\n",
    "    output = dynamic_range_compression_torch(magnitudes)\n",
    "    return output\n",
    "\n",
    "def spectral_de_normalize_torch(magnitudes):\n",
    "    output = dynamic_range_decompression_torch(magnitudes)\n",
    "    return output\n",
    "\n",
    "mel_basis = {}\n",
    "hann_window = {}\n",
    "\n",
    "def mel_spectrogram(y, n_fft, num_mels, sampling_rate, hop_size, win_size, fmin, fmax, center=False):\n",
    "    if torch.min(y) < -1.:\n",
    "        print('min value is ', torch.min(y))\n",
    "    if torch.max(y) > 1.:\n",
    "        print('max value is ', torch.max(y))\n",
    "\n",
    "    global mel_basis, hann_window\n",
    "    if fmax not in mel_basis:\n",
    "        mel = librosa_mel_fn(sr=sampling_rate, n_fft=n_fft, n_mels=num_mels, fmin=fmin, fmax=fmax)\n",
    "        mel_basis[str(fmax)+'_'+str(y.device)] = torch.from_numpy(mel).float().to(y.device)\n",
    "        hann_window[str(y.device)] = torch.hann_window(win_size).to(y.device)\n",
    "\n",
    "    y = torch.nn.functional.pad(y.unsqueeze(1), (int((n_fft-hop_size)/2), int((n_fft-hop_size)/2)), mode='reflect')\n",
    "    y = y.squeeze(1)\n",
    "\n",
    "    spec = torch.stft(y, n_fft, hop_length=hop_size, win_length=win_size, window=hann_window[str(y.device)],\n",
    "                      center=center, pad_mode='reflect', normalized=False, onesided=True, return_complex=False)\n",
    "\n",
    "    spec = torch.sqrt(spec.pow(2).sum(-1)+(1e-9))\n",
    "\n",
    "    spec = torch.matmul(mel_basis[str(fmax)+'_'+str(y.device)], spec)\n",
    "    spec = spectral_normalize_torch(spec)\n",
    "\n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222935"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsd_json_file = \"/blob/v-yuancwang/WavCaps/fsd_final_2s.json\"\n",
    "with open(fsd_json_file, \"r\") as f:\n",
    "    fsd_infos = json.load(f)\n",
    "fsd_infos = fsd_infos['data']\n",
    "# print(len(fsd_infos))\n",
    "fsd_infos_simple = []\n",
    "for info in fsd_infos:\n",
    "    fsd_infos_simple.append({\"id\": info[\"id\"], \"file_name\": info[\"file_name\"],\n",
    "                             \"download_link\": info[\"download_link\"],\n",
    "                             \"caption\": info[\"caption\"],\n",
    "                             \"duration\": info[\"duration\"]})\n",
    "# print(len(fsd_infos_simple))\n",
    "# for info in fsd_infos_simple[:5]:\n",
    "#     print(info)\n",
    "id_caption_dict = {}\n",
    "for info in fsd_infos_simple:\n",
    "    id_caption_dict[info['id']] = info['caption']\n",
    "len(id_caption_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fsd_origin_path = \"/blob/v-yuancwang/WavCaps/FreeSound/wav_origin\"\n",
    "fsd_wav_path = \"/blob/v-yuancwang/WavCaps/FreeSound/wav\"\n",
    "fsd_mel_path = \"/blob/v-yuancwang/WavCaps/FreeSound/mel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['908.wav', '416438.wav', '1985.wav', '542.wav', '1927.wav']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsd_wav_origin_lists = os.listdir(fsd_origin_path)\n",
    "print(len(fsd_wav_origin_lists))\n",
    "fsd_wav_origin_lists[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_2s_lists = []\n",
    "_5s_lists = []\n",
    "_10s_lists = []\n",
    "\n",
    "for wav_id in tqdm(fsd_wav_origin_lists[:]):\n",
    "    try:\n",
    "        wav, sr = librosa.load(os.path.join(fsd_origin_path, wav_id), sr=16000)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "    if len(wav) >= 16000 * 10:\n",
    "        wav = wav[:16000 * 10]\n",
    "    elif len(wav) < 16000 * 10 and len(wav) >= 16000 * 7:\n",
    "        wav = np.pad(wav, ((0, 16000 * 10 - len(wav))), 'wrap')\n",
    "    elif len(wav) < 16000 * 7 and len(wav) >= 16000 * 5:\n",
    "        wav = wav[:16000 * 5]\n",
    "    elif len(wav) < 16000 * 5 and len(wav) >= 16000 * 2.5:\n",
    "        wav = np.pad(wav, ((0, 16000 * 5 - len(wav))), 'wrap')\n",
    "    elif len(wav) < 16000 * 2.5 and len(wav) >= 16000 * 2:\n",
    "        wav = wav[:16000 * 2]\n",
    "    else:\n",
    "        wav = np.pad(wav, ((0, 16000 * 2 - len(wav))), 'wrap')\n",
    "    wav = np.clip(wav, -1, 1)\n",
    "\n",
    "    x = torch.FloatTensor(wav)\n",
    "    x = mel_spectrogram(x.unsqueeze(0), n_fft=1024, num_mels=80, sampling_rate=16000,\n",
    "                        hop_size=256, win_size=1024, fmin=0, fmax=8000)\n",
    "    spec = x.cpu().numpy()[0]\n",
    "    np.save(os.path.join(fsd_mel_path, wav_id.replace(\".wav\", \".npy\")), spec)\n",
    "\n",
    "    wav = wav * MAX_WAV_VALUE\n",
    "    wav = wav.astype('int16')\n",
    "    write(os.path.join(fsd_wav_path, wav_id), 16000, wav)\n",
    "\n",
    "\n",
    "print(len(_2s_lists))\n",
    "print(len(_5s_lists))\n",
    "print(len(_10s_lists))\n",
    "\n",
    "with open(\"/home/v-yuancwang/AUDIT_v2/medata_infos/fsd_2s.json\", \"w\") as f:\n",
    "    json.dump(_2s_lists, f)\n",
    "with open(\"/home/v-yuancwang/AUDIT_v2/medata_infos/fsd_5s.json\", \"w\") as f:\n",
    "    json.dump(_5s_lists, f)\n",
    "with open(\"/home/v-yuancwang/AUDIT_v2/medata_infos/fsd_10s.json\", \"w\") as f:\n",
    "    json.dump(_10s_lists, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "control",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
